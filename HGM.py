# -*- coding: utf-8 -*-
"""
@Time ï¼š 2024/9/7 22:44
@Auth ï¼š xiaolongtuan
@File ï¼šHGM.py
"""
import itertools

import networkx as nx
import numpy as np
import pulp as lp

from dataset_loader import load_dataset, process_datasets, single_bandwidth_resource, single_propagation_delay, \
    single_transmission_delay, min_bandwidth_resource, max_dalay


class HyperGraph:
    def __init__(self):
        self.nodes = set()  # è¶…å›¾ä¸­çš„èŠ‚ç‚¹é›†
        self.hyperedges = []  # è¶…è¾¹é›†

    def add_node(self, node):
        self.nodes.add(node)

    def add_hyperedge(self, nodes, weight):
        self.hyperedges.append((nodes, weight))


class HGMSolver:
    def __init__(self, SFCs, num_sfc, max_vnf_per_sfc, num_nodes,  # SFCä¿¡æ¯
                 node_cpu_capacity, node_mem_capacity, node_storage_capacity,  # èŠ‚ç‚¹èµ„æºé™åˆ¶
                 link_capacity, link_propagation_delay, link_transmission_delay,  # é“¾è·¯ä¿¡æ¯
                 R_cpu, R_memory, R_storage, R_link, tolerable_delay, safety_factor, adjacency_list):  # èµ„æºéœ€æ±‚
        self.SFCs = SFCs
        self.num_sfc = num_sfc
        self.max_vnf_per_sfc = max_vnf_per_sfc
        self.num_nodes = num_nodes
        self.node_cpu_capacity = node_cpu_capacity
        self.node_mem_capacity = node_mem_capacity
        self.node_storage_capacity = node_storage_capacity
        self.link_capacity = link_capacity
        self.link_propagation_delay = link_propagation_delay
        self.link_transmission_delay = link_transmission_delay
        self.R_cpu = R_cpu
        self.R_memory = R_memory
        self.R_storage = R_storage
        self.R_link = R_link
        self.tolerable_delay = tolerable_delay
        self.safety_factor = safety_factor
        self.L = adjacency_list

    def create_hypergraph_with_xy(self):
        H = HyperGraph()

        # Step 1: åˆå§‹åŒ– X å’Œ Y å˜é‡
        X = {}  # X[(i, f, n)] è¡¨ç¤ºç¬¬ i ä¸ª SFC çš„ç¬¬ f ä¸ª VNF æ˜¯å¦éƒ¨ç½²åœ¨ç‰©ç†èŠ‚ç‚¹ n ä¸Š
        Y = {}  # Y[(i, f, f', n, n')] è¡¨ç¤ºç¬¬ i ä¸ª SFC çš„è™šæ‹Ÿé“¾è·¯ f -> f' æ˜¯å¦ç»è¿‡ç‰©ç†é“¾è·¯ n -> n'

        # Step 2: éå†æ‰€æœ‰ SFC è¯·æ±‚ï¼Œå®šä¹‰ X å’Œ Y å˜é‡
        for i, sfc in enumerate(self.SFCs):
            # åˆå§‹åŒ– X å˜é‡ï¼šéå†æ¯ä¸ª VNF å’Œç‰©ç†èŠ‚ç‚¹
            for f, vnf in enumerate(sfc['vnfs']):
                for n in range(self.num_nodes):
                    X[(i, f, n)] = lp.LpVariable(f"X_{i}_{f}_{n}", 0, 1, lp.LpBinary)

            # åˆå§‹åŒ– Y å˜é‡ï¼šéå†æ¯ä¸ªè™šæ‹Ÿé“¾è·¯å’Œç‰©ç†é“¾è·¯
            for f in range(len(sfc['vnfs'])):
                for f_prime in range(len(sfc['vnfs'])):
                    for n in range(self.num_nodes):  # n_s æ˜¯ f çš„ç‰©ç†éƒ¨ç½²èŠ‚ç‚¹
                        for n_prime in range(self.num_nodes):  # n_t æ˜¯ f' çš„ç‰©ç†éƒ¨ç½²èŠ‚ç‚¹
                            Y[(i, f, f_prime, n, n_prime)] = lp.LpVariable(f"Y_{i}_{f}_{f_prime}_{n}_{n_prime}", 0, 1,
                                                                           lp.LpBinary)

        # Step 3: è®¡ç®—è¶…è¾¹çš„æƒé‡
        for i, sfc in enumerate(self.SFCs):
            mapped_nodes = []
            total_weight = 0
            # è®¡ç®—èŠ‚ç‚¹èµ„æºæ¶ˆè€—
            for f, vnf in enumerate(sfc['vnfs']):
                for n in range(self.num_nodes):
                    total_weight += X[(i, f, n)] * (self.R_cpu[i, f] + self.R_memory[i, f] + self.R_storage[i, f])

            # è®¡ç®—é“¾è·¯èµ„æºæ¶ˆè€—
            for f in range(len(sfc['vnfs']) - 1):
                f_prime = f + 1
                for n in range(self.num_nodes):
                    for n_prime in range(self.num_nodes):
                        total_weight += Y[(i, f, f_prime, n, n_prime)] * self.R_link[i, f, f_prime]

            for f, vnf in enumerate(sfc['vnfs']):
                for n in range(self.num_nodes):
                    if self.node_cpu_capacity[n] >= vnf['cpu_consumption'] and \
                            self.node_mem_capacity[n] >= vnf['memory_consumption'] and \
                            self.node_storage_capacity[n] >= vnf['storage_consumption']:
                        H.add_node((i, f, n))
                        mapped_nodes.append((i, f, n))

            # ä¸ºæ¯ä¸ª SFC æ·»åŠ è¶…è¾¹ï¼Œæƒé‡ä¸ºæ€»èµ„æºæ¶ˆè€—
            H.add_hyperedge(mapped_nodes, total_weight)
        return H, X, Y

    # ç®—æ³•1 å¯»æ‰¾æƒé‡æœ€å¤§çš„ç‹¬ç«‹é›†åˆ
    def ilp_solve(self):
        # åˆ›å»ºä¼˜åŒ–é—®é¢˜
        problem = lp.LpProblem("Minimize_Hyperedge_Weights", lp.LpMinimize)

        # ä» create_hypergraph_with_xy æ–¹æ³•è·å–è¶…å›¾ã€X å’Œ Y å˜é‡
        hypergraph, X, Y = self.create_hypergraph_with_xy()

        # Step 2: ç›®æ ‡å‡½æ•° - æœ€å°åŒ–è¶…è¾¹æƒé‡
        total_weight = lp.lpSum([weight for i, (nodes, weight) in enumerate(hypergraph.hyperedges)])

        problem += total_weight  # è®¾ç½®ç›®æ ‡å‡½æ•°

        # Step 3: æ·»åŠ çº¦æŸ
        problem = self.add_placement_constraints(problem, X, Y)

        # æ±‚è§£ä¼˜åŒ–é—®é¢˜
        problem.solve()

        # è¾“å‡ºç»“æœ
        print(f"Status: {lp.LpStatus[problem.status]}")
        # for var in problem.variables():
        #     print(f"{var.name} = {var.varValue}")
        self.get_results(X, Y)

        return problem

    def add_placement_constraints(self, problem, X, Y):
        # çº¦æŸ1ï¼šæ¯ä¸ªVNFå¿…é¡»æ”¾ç½®åœ¨ä¸€ä¸ªç‰©ç†èŠ‚ç‚¹ä¸Š
        for i, sfc in enumerate(self.SFCs):
            for f, vnf in enumerate(sfc['vnfs']):
                problem += lp.lpSum(X[(i, f, n)] for n in range(self.num_nodes)) == 1

        # çº¦æŸ2ï¼šæ¯ä¸ªç‰©ç†èŠ‚ç‚¹ä¸Šçš„èµ„æºæ¶ˆè€—ä¸èƒ½è¶…è¿‡èŠ‚ç‚¹å®¹é‡
        for n in range(self.num_nodes):
            problem += lp.lpSum(X[(i, f, n)] * self.R_cpu[i][f] for i, sfc in enumerate(self.SFCs) for f, _ in
                                enumerate(sfc['vnfs'])) <= self.node_cpu_capacity[n]
            problem += lp.lpSum(X[(i, f, n)] * self.R_memory[i][f] for i, sfc in enumerate(self.SFCs) for f, _ in
                                enumerate(sfc['vnfs'])) <= self.node_mem_capacity[n]
            problem += lp.lpSum(X[(i, f, n)] * self.R_storage[i][f] for i, sfc in enumerate(self.SFCs) for f, _ in
                                enumerate(sfc['vnfs'])) <= self.node_storage_capacity[n]

        # çº¦æŸ3ï¼šç‰©ç†é“¾è·¯ä¸Šçš„èµ„æºæ¶ˆè€—ä¸èƒ½è¶…è¿‡é“¾è·¯å¸¦å®½ï¼Œ åŒå‘çš„é“¾è·¯å ç”¨ä¹‹å’Œä¸èƒ½è¶…è¿‡é“¾è·¯å®¹é‡
        for (n, n_prime), capacity in self.link_capacity.items():
            problem += (lp.lpSum(Y[(i, f, f_prime, n, n_prime)] * self.R_link[i][f][f_prime]
                                 for i, sfc in enumerate(self.SFCs)
                                 for f, _ in enumerate(sfc['vnfs'])
                                 for f_prime, _ in enumerate(sfc['vnfs'])) +
                        lp.lpSum(Y[(i, f, f_prime, n_prime, n)] * self.R_link[i][f][f_prime]
                                 for i, sfc in enumerate(self.SFCs)
                                 for f, _ in enumerate(sfc['vnfs'])
                                 for f_prime, _ in enumerate(sfc['vnfs']))) <= capacity
        # çº¦æŸ4ï¼šæ¯ä¸ªSFCçš„å»¶è¿Ÿä¸èƒ½è¶…è¿‡å®¹å¿å»¶è¿Ÿ
        for i, sfc in enumerate(self.SFCs):
            total_delay = 0

            # éå† SFC çš„è™šæ‹Ÿé“¾è·¯
            for f in range(sfc['num_vnf'] - 1):
                f_prime = f + 1

                # ä¼ æ’­å’Œä¼ è¾“å»¶è¿Ÿ
                propagation_delay = lp.lpSum(
                    Y[(i, f, f_prime, n, n_prime)] * (
                        self.link_propagation_delay[(n, n_prime)] if (n, n_prime) in self.link_propagation_delay else
                        self.link_propagation_delay[(n_prime, n)])
                    for n in range(self.num_nodes) for n_prime in range(self.num_nodes))

                transmission_delay = lp.lpSum(
                    Y[(i, f, f_prime, n, n_prime)] * (
                        self.link_transmission_delay[(n, n_prime)] if (n, n_prime) in self.link_transmission_delay else
                        self.link_transmission_delay[(n_prime, n)])
                    for n in range(self.num_nodes) for n_prime in range(self.num_nodes))

                # æ’é˜Ÿå»¶è¿Ÿ
                queue_delay = lp.lpSum(Y[(i, f, f_prime, n, n_prime)] * (
                        self.R_link[i, f, f_prime] /
                        (self.link_capacity[(n, n_prime)] if (n, n_prime) in self.link_capacity else self.link_capacity[
                            (n_prime, n)]))
                                       for n in range(self.num_nodes) for n_prime in range(self.num_nodes))

                # å¤„ç†å»¶è¿Ÿ
                processing_delay = lp.lpSum(X[(i, f, n)] * (self.R_cpu[i, f] / self.node_cpu_capacity[n])
                                            for n in range(self.num_nodes))

                total_delay += propagation_delay + transmission_delay + queue_delay + processing_delay

            # æœ€åä¸€ä¸ªVNFçš„å¤„ç†å»¶è¿Ÿ
            total_delay += lp.lpSum(
                X[(i, sfc['num_vnf'] - 1, n)] * (self.R_cpu[i, sfc['num_vnf'] - 1] / self.node_cpu_capacity[n])
                for n in range(self.num_nodes))

            # æ·»åŠ çº¦æŸï¼šç¡®ä¿ç«¯åˆ°ç«¯å»¶è¿Ÿå°äºæˆ–ç­‰äº SFC çš„å¯å®¹å¿å»¶è¿Ÿ
            problem += total_delay <= sfc['max_latency'], f"Delay_Constraint_SFC_{i}"

        # çº¦æŸ5 é“¾è·¯éƒ¨ç½²
        # ä¸ºæ¯æ¡è™šæ‹Ÿé“¾è·¯ ff' æ·»åŠ è·¯å¾„è¿ç»­æ€§å’Œæµé‡å®ˆæ’çº¦æŸ
        for i, sfc in enumerate(self.SFCs):
            for f, _ in enumerate(sfc['vnfs'][:-1]):
                f_prime = f + 1  # f' æ˜¯ç›¸é‚»çš„ VNF
                for n_s in range(self.num_nodes):  # n_s æ˜¯ f çš„ç‰©ç†éƒ¨ç½²èŠ‚ç‚¹
                    for n_t in range(self.num_nodes):  # n_t æ˜¯ f' çš„ç‰©ç†éƒ¨ç½²èŠ‚ç‚¹
                        if n_s != n_t:
                            '''
                            # æºèŠ‚ç‚¹æµå‡ºçº¦æŸï¼šä»æºèŠ‚ç‚¹ n_s å¿…é¡»æœ‰ä¸€æ¡ç‰©ç†é“¾è·¯æµå‡º
                            problem += (
                                    lp.lpSum(Y[i, f, f_prime, n_s, n_p] for n_p in range(self.num_nodes) if
                                             (n_s, n_p) in self.L) == 1
                            )
                            # ç›®çš„èŠ‚ç‚¹æµå…¥çº¦æŸï¼šå¿…é¡»æœ‰ä¸€æ¡ç‰©ç†é“¾è·¯æµå…¥ç›®çš„èŠ‚ç‚¹ n_t
                            problem += (
                                    lp.lpSum(Y[i, f, f_prime, n_p, n_t] for n_p in range(self.num_nodes) if
                                             (n_p, n_t) in self.L) == 1
                            )
                            # ä¸­é—´èŠ‚ç‚¹çš„æµé‡å®ˆæ’çº¦æŸï¼šå¯¹äºä¸­é—´èŠ‚ç‚¹ï¼Œæµå…¥ç­‰äºæµå‡º
                            for n in range(self.num_nodes):
                                if n != n_s and n != n_t:
                                    problem += (
                                            lp.lpSum(Y[i, f, f_prime, n_p, n] for n_p in range(self.num_nodes) if
                                                     (n_p, n) in self.L) ==
                                            lp.lpSum(Y[i, f, f_prime, n, n_p] for n_p in range(self.num_nodes) if
                                                     (n, n_p) in self.L)
                                    )
                            '''
                            # è™šæ‹Ÿé“¾è·¯çš„èµ·ç‚¹å’Œç»ˆç‚¹å¿…é¡»ä¸ VNF çš„ç‰©ç†éƒ¨ç½²ä½ç½®ä¸€è‡´
                            problem += (Y[i, f, f_prime, n_s, n_t] <= X[i, f, n_s])
                            problem += (Y[i, f, f_prime, n_s, n_t] <= X[i, f_prime, n_t])
                        else:
                            problem += (Y[i, f, f_prime, n_s, n_t] == 0)
        return problem

    def HGM_solve(self):
        H, X, Y = self.create_hypergraph_with_xy()
        conflict_graph = self.create_conflict_graph(H)
        S = self.vertex_set_search_algorithm(conflict_graph)
        S = self.phi_claw_local_search_algorithm(S, conflict_graph)

        return S

    def get_results(self, X, Y):
        # æå–ç»“æœ
        placement_results = []
        link_results = []

        for i, sfc in enumerate(self.SFCs):
            for f, _ in enumerate(sfc['vnfs']):
                for n in range(self.num_nodes):
                    if lp.value(X[(i, f, n)]) == 1:
                        placement_results.append((i, f, n))

        for i, sfc in enumerate(self.SFCs):
            for f, _ in enumerate(sfc['vnfs']):
                for f_prime, _ in enumerate(sfc['vnfs']):
                    for n in range(self.num_nodes):
                        for n_prime in range(self.num_nodes):
                            if lp.value(Y[(i, f, f_prime, n, n_prime)]) == 1:
                                link_results.append((i, f, f_prime, n, n_prime))
        print({'placement': placement_results, 'links': link_results})
        return

    def create_conflict_graph(self, hypergraph: HyperGraph):
        """
        æ ¹æ®ç»™å®šçš„è¶…å›¾ H æ„é€ å†²çªå›¾ Ï†ã€‚

        :param hypergraph: å·²æ„å»ºçš„è¶…å›¾ Hï¼Œå…¶ä¸­æ¯ä¸ªè¶…è¾¹æœ‰ä¸èµ„æºå ç”¨ç›¸å…³çš„æƒé‡ã€‚
        :return: å†²çªå›¾ Ï†
        """
        # åˆå§‹åŒ–å†²çªå›¾ Ï†
        conflict_graph = nx.Graph()

        # Step 1: æ·»åŠ è¶…å›¾ä¸­çš„æ¯ä¸ªè¶…è¾¹ä½œä¸ºå†²çªå›¾ä¸­çš„é¡¶ç‚¹ï¼Œå¹¶è®¾ç½®æƒé‡
        hyperedges = hypergraph.hyperedges
        for i, (nodes, weight) in enumerate(hyperedges):
            conflict_graph.add_node(i, weight=weight)

        # Step 2: æ£€æŸ¥è¶…å›¾ä¸­å“ªäº›è¶…è¾¹å…±äº«èŠ‚ç‚¹ï¼Œæ„å»ºå†²çªè¾¹
        for edge1, edge2 in itertools.combinations(self.hyperedges, 2):
            # æ£€æŸ¥æ˜¯å¦å…±äº«ä»»ä½• VNF æˆ–ç‰©ç†èŠ‚ç‚¹
            nodes1 = {n for _, _, n in edge1}
            nodes2 = {n for _, _, n in edge2}
            # å¦‚æœä¸¤ä¸ªè¶…è¾¹å…±äº«è‡³å°‘ä¸€ä¸ªç‰©ç†èŠ‚ç‚¹æˆ– VNFï¼Œåˆ™æ·»åŠ å†²çªè¾¹
            if nodes1 & nodes2:
                conflict_graph.add_edge(edge1, edge2)
        return conflict_graph

    def vertex_set_search_algorithm(self, conflict_graph):
        # Initialization: Initialize the independent set S
        S = set()
        Z = set(conflict_graph.nodes)

        while Z:
            # Choose the vertex with the maximum weight from Z
            z_max = max(Z, key=lambda z: conflict_graph.nodes[z]['weight'])
            S.add(z_max)

            # Find all adjacent vertices of z_max
            B_max = set(conflict_graph.neighbors(z_max))

            # Update Z by removing z_max and its neighbors
            Z -= {z_max}
            Z -= B_max

        # Return the selected independent set S
        return S

    # ç®—æ³•2
    def phi_claw_local_search_algorithm(self, S, conflict_graph):
        # Step 1: Rank vertices in S based on their weights
        S = sorted(S, key=lambda v: conflict_graph.nodes[v]['weight'], reverse=True)

        i = 0
        while i < len(S):
            current_vertex = S[i]
            B_i = list(conflict_graph.neighbors(current_vertex))
            B_i = sorted(B_i, key=lambda v: conflict_graph.nodes[v]['weight'], reverse=True)

            # Step 5: Set the i-th vertex as the center vertex of ğœ™-claw
            for phi in range(1, 4):
                found_claw = False

                for j in range(len(B_i)):
                    candidate_set = set([current_vertex] + B_i[:phi])

                    # Check if candidate set forms a valid ğœ™-claw in the conflict graph
                    if all(not conflict_graph.has_edge(x, y) for x in candidate_set for y in candidate_set if x != y):
                        found_claw = True
                        new_S = (set(S) - set(B_i)) | candidate_set

                        # Check if the weight of the new set is greater than the current set
                        if sum(conflict_graph.nodes[v]['weight'] for v in new_S) > sum(
                                conflict_graph.nodes[v]['weight'] for v in S):
                            S = new_S
                            i = 0  # Restart the search from the beginning with the new S
                            break

                if found_claw:
                    break

            i += 1

        return S


def run_solver_on_dataset(dataset):
    # ä»æ•°æ®é›†ä¸­æå–ç½‘ç»œæ‹“æ‰‘å’Œèµ„æºä¿¡æ¯
    network_topology = dataset['network_topology']
    network_resources = dataset['network_resources']
    sfc_data = dataset['sfcs']
    adjacency_list = dataset['adjacency_list']

    # æå–ç‰©ç†èŠ‚ç‚¹å’Œé“¾è·¯çš„èµ„æº
    num_nodes = len(network_topology.nodes)
    node_cpu_capacity = [network_resources[n]['cpu_resource'] for n in range(num_nodes)]
    node_mem_capacity = [network_resources[n]['memory_resource'] for n in range(num_nodes)]
    node_storage_capacity = [network_resources[n]['storage_resource'] for n in range(num_nodes)]

    for n in range(num_nodes):
        for n_prime in range(num_nodes):
            if n == n_prime:  # åŒä¸€è®¾å¤‡
                network_resources[(n, n_prime)] = {
                    'bandwidth_resource': single_bandwidth_resource,
                    'propagation_delay': single_propagation_delay,
                    'transmission_delay': single_transmission_delay
                }
            if ((n, n_prime) not in network_resources) or ((n_prime, n) not in network_resources):  # æ²¡æœ‰é“¾è·¯
                network_resources[(n, n_prime)] = {
                    'bandwidth_resource': min_bandwidth_resource,
                    'propagation_delay': max_dalay,
                    'transmission_delay': max_dalay
                }

    link_capacity = {k: v['bandwidth_resource']
                     for k, v in network_resources.items() if isinstance(k, tuple)}
    link_propagation_delay = {k: v['propagation_delay']
                              for k, v in network_resources.items() if isinstance(k, tuple)}
    link_transmission_delay = {k: v['transmission_delay']
                               for k, v in network_resources.items() if isinstance(k, tuple)}

    # æå–SFCä¿¡æ¯
    num_sfc = len(sfc_data)
    vnf_per_sfc = [sfc['num_vnf'] for sfc in sfc_data]
    max_vnf_per_sfc = max(vnf_per_sfc)

    # åˆ›å»ºèµ„æºéœ€æ±‚çŸ©é˜µ R_cpu, R_memory, R_storage
    R_cpu = np.zeros((num_sfc, max_vnf_per_sfc))  # CPUèµ„æºçŸ©é˜µ
    R_memory = np.zeros((num_sfc, max_vnf_per_sfc))  # å†…å­˜èµ„æºçŸ©é˜µ
    R_storage = np.zeros((num_sfc, max_vnf_per_sfc))  # å­˜å‚¨èµ„æºçŸ©é˜µ
    # åˆ›å»ºè™šæ‹Ÿé“¾è·¯å¸¦å®½éœ€æ±‚çŸ©é˜µ R_link(i, f, f')
    R_link = np.zeros((num_sfc, max_vnf_per_sfc, max_vnf_per_sfc))
    tolerable_delay = np.zeros((num_sfc,))  # å¯å®¹å¿çš„å»¶è¿Ÿ
    safety_factor = np.zeros((num_sfc,))

    for i, sfc in enumerate(sfc_data):
        tolerable_delay[i] = sfc['max_latency']
        safety_factor[i] = sfc['safety_factor']

        for f, vnf in enumerate(sfc['vnfs']):
            R_cpu[i, f] = vnf['cpu_consumption']
            R_memory[i, f] = vnf['memory_consumption']
            R_storage[i, f] = vnf['storage_consumption']
        for f, link in enumerate(sfc['links']):
            bandwidth = link['bandwidth_consumption']
            R_link[i, f, f + 1] = bandwidth

    # åˆ›å»ºæ±‚è§£å™¨å¹¶æ±‚è§£
    hgm_solver = HGMSolver(sfc_data, num_sfc, max_vnf_per_sfc, num_nodes, node_cpu_capacity, node_mem_capacity,
                           node_storage_capacity, link_capacity, link_propagation_delay,
                           link_transmission_delay,
                           R_cpu, R_memory, R_storage, R_link, tolerable_delay, safety_factor, adjacency_list)
    hgm_solver.ilp_solve()


if __name__ == '__main__':
    file_path = 'data/sfc_datasets.json'
    datasets = load_dataset(file_path)
    processed_datasets = process_datasets(datasets)
    run_solver_on_dataset(processed_datasets[0])
